{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import pyautogui as pyag\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "#from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholds and consecutive frame length for triggering the mouse action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUTH_AR_THRESH = 0.6\n",
    "MOUTH_AR_CONSECUTIVE_FRAMES = 15\n",
    "EYE_AR_THRESH = 0.19\n",
    "EYE_AR_CONSECUTIVE_FRAMES = 15\n",
    "WINK_AR_DIFF_THRESH = 0.04\n",
    "WINK_AR_CLOSE_THRESH = 0.19\n",
    "WINK_CONSECUTIVE_FRAMES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the frame counters for each action as well as<br>\n",
    "booleans used to indicate if action is performed or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MOUTH_COUNTER = 0\n",
    "EYE_COUNTER = 0\n",
    "WINK_COUNTER = 0\n",
    "INPUT_MODE = False\n",
    "EYE_CLICK = False\n",
    "LEFT_WINK = False\n",
    "RIGHT_WINK = False\n",
    "SCROLL_MODE = False\n",
    "ANCHOR_POINT = (0, 0)\n",
    "WHITE_COLOR = (255, 255, 255)\n",
    "YELLOW_COLOR = (0, 255, 255)\n",
    "RED_COLOR = (0, 0, 255)\n",
    "GREEN_COLOR = (0, 255, 0)\n",
    "BLUE_COLOR = (255, 0, 0)\n",
    "BLACK_COLOR = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Dlib's face detector (HOG-based) and then create<br>\n",
    "the facial landmark predictor<br>\n",
    "=Path(\"model\")<br>\n",
    "hape_predictor = \"model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"venv/Lib/site-packages/face_recognition_models/models/shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the indexes of the facial landmarks for the left and<br>\n",
    "right eye, nose and mouth respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
    "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
    "(nStart, nEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"nose\"]\n",
    "(mStart, mEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"mouth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "resolution_w = 1366\n",
    "resolution_h = 768\n",
    "cam_w = 640\n",
    "cam_h = 480\n",
    "unit_w = resolution_w / cam_w\n",
    "unit_h = resolution_h / cam_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "    # channels)\n",
    "    _, frame = vid.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = imutils.resize(frame, width=cam_w, height=cam_h)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "\n",
    "    # Loop over the face detections\n",
    "    if len(rects) > 0:\n",
    "        rect = rects[0]\n",
    "    else:\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        continue\n",
    "\n",
    "    # Determine the facial landmarks for the face region, then\n",
    "    # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "    # array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "    # Extract the left and right eye coordinates, then use the\n",
    "    # coordinates to compute the eye aspect ratio for both eyes\n",
    "    mouth = shape[mStart:mEnd]\n",
    "    leftEye = shape[lStart:lEnd]\n",
    "    rightEye = shape[rStart:rEnd]\n",
    "    nose = shape[nStart:nEnd]\n",
    "\n",
    "    # Because I flipped the frame, left is right, right is left.\n",
    "    temp = leftEye\n",
    "    leftEye = rightEye\n",
    "    rightEye = temp\n",
    "\n",
    "    # Average the mouth aspect ratio together for both eyes\n",
    "    mar = mouth_aspect_ratio(mouth)\n",
    "    leftEAR = eye_aspect_ratio(leftEye)\n",
    "    rightEAR = eye_aspect_ratio(rightEye)\n",
    "    ear = (leftEAR + rightEAR) / 2.0\n",
    "    diff_ear = np.abs(leftEAR - rightEAR)\n",
    "    nose_point = (nose[3, 0], nose[3, 1])\n",
    "\n",
    "    # Compute the convex hull for the left and right eye, then\n",
    "    # visualize each of the eyes\n",
    "    mouthHull = cv2.convexHull(mouth)\n",
    "    leftEyeHull = cv2.convexHull(leftEye)\n",
    "    rightEyeHull = cv2.convexHull(rightEye)\n",
    "    cv2.drawContours(frame, [mouthHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [leftEyeHull], -1, YELLOW_COLOR, 1)\n",
    "    cv2.drawContours(frame, [rightEyeHull], -1, YELLOW_COLOR, 1)\n",
    "    for (x, y) in np.concatenate((mouth, leftEye, rightEye), axis=0):\n",
    "        cv2.circle(frame, (x, y), 2, GREEN_COLOR, -1)\n",
    "\n",
    "    # Check to see if the eye aspect ratio is below the blink\n",
    "    # threshold, and if so, increment the blink frame counter\n",
    "    if diff_ear > WINK_AR_DIFF_THRESH:\n",
    "        if leftEAR < rightEAR:\n",
    "            if leftEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pyag.click(button='left')\n",
    "                    WINK_COUNTER = 0\n",
    "        elif leftEAR > rightEAR:\n",
    "            if rightEAR < EYE_AR_THRESH:\n",
    "                WINK_COUNTER += 1\n",
    "                if WINK_COUNTER > WINK_CONSECUTIVE_FRAMES:\n",
    "                    pyag.click(button='right')\n",
    "                    WINK_COUNTER = 0\n",
    "        else:\n",
    "            WINK_COUNTER = 0\n",
    "    else:\n",
    "        if ear <= EYE_AR_THRESH:\n",
    "            EYE_COUNTER += 1\n",
    "            if EYE_COUNTER > EYE_AR_CONSECUTIVE_FRAMES:\n",
    "                SCROLL_MODE = not SCROLL_MODE\n",
    "                # INPUT_MODE = not INPUT_MODE\n",
    "                EYE_COUNTER = 0\n",
    "                # nose point to draw a bounding box around it\n",
    "        else:\n",
    "            EYE_COUNTER = 0\n",
    "            WINK_COUNTER = 0\n",
    "    if mar > MOUTH_AR_THRESH:\n",
    "        MOUTH_COUNTER += 1\n",
    "        if MOUTH_COUNTER >= MOUTH_AR_CONSECUTIVE_FRAMES:\n",
    "            # if the alarm is not on, turn it on\n",
    "            INPUT_MODE = not INPUT_MODE\n",
    "            # SCROLL_MODE = not SCROLL_MODE\n",
    "            MOUTH_COUNTER = 0\n",
    "            ANCHOR_POINT = nose_point\n",
    "    else:\n",
    "        MOUTH_COUNTER = 0\n",
    "    if INPUT_MODE:\n",
    "        cv2.putText(frame, \"READING INPUT!\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        x, y = ANCHOR_POINT\n",
    "        nx, ny = nose_point\n",
    "        w, h = 60, 35\n",
    "        multiple = 1\n",
    "        cv2.rectangle(frame, (x - w, y - h), (x + w, y + h), GREEN_COLOR, 2)\n",
    "        cv2.line(frame, ANCHOR_POINT, nose_point, BLUE_COLOR, 2)\n",
    "        dir = direction(nose_point, ANCHOR_POINT, w, h)\n",
    "        cv2.putText(frame, dir.upper(), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "        drag = 18\n",
    "        if dir == 'right':\n",
    "            pyag.moveRel(drag, 0)\n",
    "        elif dir == 'left':\n",
    "            pyag.moveRel(-drag, 0)\n",
    "        elif dir == 'up':\n",
    "            if SCROLL_MODE:\n",
    "                pyag.scroll(40)\n",
    "            else:\n",
    "                pyag.moveRel(0, -drag)\n",
    "        elif dir == 'down':\n",
    "            if SCROLL_MODE:\n",
    "                pyag.scroll(-40)\n",
    "            else:\n",
    "                pyag.moveRel(0, drag)\n",
    "    if SCROLL_MODE:\n",
    "        cv2.putText(frame, 'SCROLL MODE IS ON!', (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, RED_COLOR, 2)\n",
    "\n",
    "    # cv2.putText(frame, \"MAR: {:.2f}\".format(mar), (500, 30),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Right EAR: {:.2f}\".format(rightEAR), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Left EAR: {:.2f}\".format(leftEAR), (460, 130),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, YELLOW_COLOR, 2)\n",
    "    # cv2.putText(frame, \"Diff EAR: {:.2f}\".format(np.abs(leftEAR - rightEAR)), (460, 80),\n",
    "    #             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "    # Show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # If the `Esc` key was pressed, break from the loop\n",
    "    if key == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a bit of cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
